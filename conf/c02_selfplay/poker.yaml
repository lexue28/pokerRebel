defaults:
  - optimizer: adam

seed: 0

# Device: "cuda" for GPU training, "cpu" for CPU-only
# If PyTorch doesn't have CUDA support, set to "cpu"
device: cpu

# Learning rate schedule
decrease_lr_every: 400
decrease_lr_times: 2
grad_clip: 5.0

env:
  # Poker variant identifier (used by env factory)
  game: toss_holdem

  # Exploration during SAMPLELEAF
  random_action_prob: 0.25
  sample_leaf: true

  subgame_params:
    # CFR iterations per subgame
    # STRONG config matching run_cpu_batch_strong.sh for better gameplay
    # These values are explicitly set in the batch script, but having them here ensures
    # they're used even if someone runs without the batch script
    num_iters: 64         # Strong config for gameplay (matches .sh script)
    max_depth: 3          # Strong config for gameplay (matches .sh script)
    linear_update: true

# NOTE: exploitability evaluation uses the C++ solver + TorchScript net and may
# attempt CUDA paths. Keep this off for CPU-only PyTorch builds.
exploit: false

selfplay:
  network_sync_epochs: 1
  dump_dataset_every_epochs: 200

  # GPU settings (disabled)
  threads_per_gpu: -1
  models_per_gpu: 1

  # CPU-only data generation
  cpu_gen_threads: 4      # Strong config (matches .sh script) - was 1 for ultra-safe

train_gen_ratio: 4
task: selfplay

loss: huber

min_buffer_to_send: 2500
max_epochs: 1500          # Reduced from 3000 - loss typically plateaus around 1000-1500 epochs
                          # With stronger config (64 iters, 3 depth), 1500 should be sufficient
                          # Can always stop early if loss plateaus (checkpoints every 10 epochs)

model:
  name: Net2
  kwargs:
    n_hidden: 256
    n_layers: 2
    use_layer_norm: true

create_validation_set_every: 100

data:
  train_epoch_size: 1600  # Reduced from 3200 - faster training start, still good quality
  train_batch_size: 128   # Strong config (matches .sh script) - was 16 for ultra-safe

replay:
  capacity: 50000         # Strong config (matches .sh script) - was 1000 for ultra-safe
  alpha: 1.0
  beta: 1.0
  prefetch: 8
  use_priority: false
