defaults:
  - optimizer: adam

seed: 0

# Device: "cuda" for GPU training, "cpu" for CPU-only
# If PyTorch doesn't have CUDA support, set to "cpu"
device: cuda

# Learning rate schedule
decrease_lr_every: 400
decrease_lr_times: 2
grad_clip: 5.0

env:
  # Poker variant identifier (used by env factory)
  game: toss_holdem

  # Exploration during SAMPLELEAF
  random_action_prob: 0.25
  sample_leaf: true

  subgame_params:
    # CFR iterations per subgame
    num_iters: 256        # MUCH smaller than paper, CPU-safe
    max_depth: 4          # Enough to cover discard + betting
    linear_update: true

exploit: true

selfplay:
  network_sync_epochs: 1
  dump_dataset_every_epochs: 200

  # GPU settings (disabled)
  threads_per_gpu: -1
  models_per_gpu: 1

  # CPU-only data generation
  cpu_gen_threads: 8      # Do NOT use 60 on a laptop

train_gen_ratio: 4
task: selfplay

loss: huber

min_buffer_to_send: 2500
max_epochs: 3000          # Smaller than LD

model:
  name: Net2
  kwargs:
    n_hidden: 256
    n_layers: 2
    use_layer_norm: true

create_validation_set_every: 100

data:
  train_epoch_size: 12800
  train_batch_size: 512

replay:
  capacity: 500000        # Smaller buffer for poker prototype
  alpha: 1.0
  beta: 1.0
  prefetch: 8
  use_priority: false
